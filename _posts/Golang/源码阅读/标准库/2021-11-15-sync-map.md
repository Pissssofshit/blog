---
title: sync.map源码解读
category: [Golang]
layout: post
tags: [Golang,源码阅读]
---

直接上代码

```
func (m *Map) Load(key any) (value any, ok bool) {
	read, _ := m.read.Load().(readOnly)
	e, ok := read.m[key]
	if !ok && read.amended { // 不在read中，在dirty中
		m.mu.Lock()
		read, _ = m.read.Load().(readOnly)
		e, ok = read.m[key]
		if !ok && read.amended { // 二次确认，防止在阻塞获取锁的过程中dirty进行了”提升“
			e, ok = m.dirty[key]
			m.missLocked() // 统计miss次数，达到一定阈值更新read,详情见下面给出的代码
		}
		m.mu.Unlock()
	}
	if !ok {
		return nil, false
	}
	return e.load()
}

func (m *Map) missLocked() {
	m.misses++  // 增加miss的统计次数
	if m.misses < len(m.dirty) { // miss次数小于dirty元素个数就不更新
		return
	}
	m.read.Store(readOnly{m: m.dirty}) // 将read更新为dirty的值,即所说的”提升“操作
	m.dirty = nil
	m.misses = 0
}
```

#### 为什么选择len(map)这个大小为阈值？

`sync.Map` 选择在 `misses` 计数器大于等于 `dirty` map 长度时进行提升操作，是为了在性能和内存占用之间取得一个平衡。让我们详细解释一下这个策略背后的原因。

在 `sync.Map` 中，`dirty` map 存储了可能需要更新的键值对，而 `read` map 则存储了相对稳定的键值对。这种设计主要是为了避免读操作因为写操作的竞争而阻塞。如果提升操作发生得过于频繁，那么每次写操作都会导致提升，从而增加了读操作的开销。相反，如果提升操作发生得过于稀疏，那么 `dirty` map 会变得很大，导致内存占用增加。

当 `misses` 计数器大于等于 `dirty` map 的长度时进行提升操作，可以在以下几个方面实现性能和内存占用的平衡：

1. 限制内存占用：当 `misses` 达到 `dirty` map 长度时，说明有足够多的键值对需要从 `dirty` map 提升到 `read` map。这样可以防止 `dirty` map 变得过大，从而降低内存占用。
2. 减少竞争：这个策略可以确保 `read` map 中的键值对相对稳定，从而减少读操作中的竞争。因为在提升操作期间，读操作会使用新的 `read` map，而写操作会继续使用 `dirty` map，从而避免了直接竞争。
3. 延迟提升：当 `misses` 较小时，表示读操作能够在 `read` map 中找到所需的键值对，这时不需要立即进行提升操作。这样可以延迟提升操作的执行，降低读操作的开销。

#### 为什么read字段使用atomic.Value

atomic.Value 提供了一种原子访问共享变量的方法，它可以在多个 goroutine 之间安全地读写变量。它的实现原理基于 CPU 提供的原子指令，如 CMPXCHG（比较并交换），这些原子指令可以在单个 CPU 操作中完成读取、修改和写入操作。这样，即使在多个 goroutine 同时访问变量时，也不会出现数据竞争或不一致的状态。

#### 既然是atomic.Value是并发读写安全的数据结构，为什么dirty还是使用普通的map

`sync.Map` 的设计目标是为了在高并发读场景下提供更好的性能。在这种场景下，使用 `atomic.Value` 无锁地进行读操作的开销是小于使用锁的。但是，写操作的性能特征与读操作不同。当涉及到写操作时，原子操作可能会引入更多的性能开销，尤其是当写操作需要处理复杂数据结构（如 map）时。在这种情况下，使用锁和普通数据结构进行写操作可能会比原子操作具有更好的性能。

#### 为什么read字段要使用atomic.Value而不是普通的map

如果read真的只是单纯的读，那么使用普通map是没有问题的。可是在提升的时候，会存在并发读写的问题，因此如果不加锁保护的话，将会发生`数据竞争`的问题。 因此将 `read` 字段更改为普通 map 将导致的问题可以总结为：

1. **锁的开销**：将 `read` 字段更改为普通 map 后，我们需要在读操作中使用锁来避免数据竞争。这是因为，尽管读操作和写操作已经分离，但在提升操作期间，`read` map 仍然可能发生变化。加锁会带来额外的开销，可能导致性能下降。
2. **更高的竞争**：使用普通 map 作为 `read` 字段意味着我们需要在读操作中加锁。这可能导致读操作之间的竞争增加，尤其是在高并发读场景下。这会降低 `sync.Map` 的性能，违背了其设计初衷。

### 总结


总的来说，`read` 包含了许多稳定的键值对，而 `dirty` 包含了 `read` 中可能不存在的键值对以及可能发生更新的键值对。在读操作中，首先从 `read` 中读取数据，因为 `atomic.Value` 是并发读写安全的数据结构，所以是安全的。如果 `read` 中不存在需要的值，则需要加锁并访问 `dirty`。

当 `miss` 达到一个阈值时（具体而言，当 `miss` 计数器的值大于等于 `dirty` map 的长度时），会触发提升操作。在提升操作中，`dirty` map 的内容会被复制到 `read` map，然后将 `dirty` map 置为 `nil` 并重置 `miss` 计数器。通过这种方式，`sync.Map` 在高并发读场景下能够减少锁的使用，从而提高性能。



```
数据竞争（Data Race）是指在多线程或多协程的环境中，两个或多个操作同时访问同一内存位置，且至少有一个操作是写入的情况。在数据竞争发生时，操作的执行顺序是不确定的，这可能导致不可预测的结果和程序行为。因此，数据竞争可能导致未定义的行为和程序错误。

让我们深入了解一下数据竞争的底层原理：

CPU 缓存和内存一致性：现代 CPU 通常具有缓存，用于存储最近访问过的内存数据，以提高性能。多核 CPU 每个核心都有自己的缓存。当多个核心同时访问同一内存位置时，可能会发生数据竞争。为了确保内存一致性，CPU 需要在各个核心间同步缓存的数据。如果没有适当的同步机制，这可能导致内存数据不一致，从而导致未定义的行为和程序错误。

编译器优化：编译器可能会对代码进行优化，以提高性能。这些优化可能包括重新排序指令、消除冗余操作等。在多线程或多协程的环境中，如果没有适当的同步机制，编译器优化可能导致数据竞争和未定义的行为。

指令重排：为了提高性能，现代 CPU 可能会对指令进行重新排序。在多线程或多协程的环境中，如果没有适当的同步机制，指令重排可能导致数据竞争和未定义的行为。

为了避免数据竞争和相关的问题，我们需要在多线程或多协程的环境中使用适当的同步机制，如锁（Mutex）或原子操作（Atomic Operation）。这些同步机制可以确保操作按预期的顺序执行，从而避免数据竞争和未定义的行为。

在 Go 语言中，当多个 goroutine 同时访问共享数据时，我们需要使用同步原语（如 sync.Mutex 或原子操作）来确保数据的一致性和正确性。如果不使用这些同步原语，可能会导致数据竞争和程序错误。
```

